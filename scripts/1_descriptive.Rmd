---
title: "The relationship between expectation and performance: Methodological evaluation"
author: "Aleksandra Ćwiek, Wim Pouw, Susanne Fuchs, Šárka Kadavá"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  rmarkdown::html_document:
    theme: readable
    number_sections: yes
    toc: yes
    toc_depth: 4
    toc_float: yes
    df_print: paged
    code_folding: hide
  pdf_document:
    number_sections: yes
    toc: yes
    toc_depth: '3'
  html_notebook:
    number_sections: yes
    toc: yes
    toc_depth: 3
    toc_float: yes
editor_options: 
  chunk_output_type: console
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

This is the preparation and descriptive analysis of expressibility vs.
guessability, preregistered at
[AsPredicted](https://aspredicted.org/kmry-vx5s.pdf).

# Data preparation

## Source setup

```{r source setup, echo = TRUE, message=FALSE, warning = FALSE}

########## folders ##########
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))

parentfolder <- dirname(getwd())

rawdata       <- paste0(parentfolder, '/rawdata/')
dataset       <- paste0(parentfolder, '/dataset/')
models        <- paste0(parentfolder, '/models/')
plots         <- paste0(parentfolder, '/plots/')
scripts       <- paste0(parentfolder, '/scripts/')

########## source file ##########

#source(paste0(scripts, "adjectives-preparation.R"))

#################### packages ####################
# Data Manipulation
library(tibble)
library(stringr)
library(tidyverse) # includes readr, tidyr, dplyr, ggplot2
packageVersion("tidyverse")
library(data.table)
library(readxl)

# Plotting
library(ggforce)
library(ggpubr)
library(gridExtra)
library(corrplot)
library(ggdist)
library(ggbeeswarm)

library(BayesFactor)

# use all available cores for parallel computing
options(mc.cores = parallel::detectCores())

colorBlindBlack8  <- c("#000000", "#E69F00", "#56B4E9", "#009E73", 
                       "#F0E442", "#0072B2", "#D55E00", "#CC79A7")

```

## Load in data frames

```{r read metadata, echo=TRUE, message=FALSE, warning=FALSE}
# Load data frame
df <- read_csv(paste0(dataset, "similarity_df_final.csv"))

# Load concept list
concepts <- read_excel(paste0(dataset, "conceptlist_info.xlsx"))

# Load expressibility German
expr_german <- read_csv(paste0(dataset, "expressibility_german.csv"))

# Load expressibility Dutch
expr_dutch <- read_csv(paste0(dataset, "expressibility_dutch.csv"))

```

## Cleaning

```{r}
df <- df %>%
  mutate(
    modality = case_when(
      modality == "combinatie" ~ "combined",
      modality == "gebaren" ~ "gesture",
      modality == "geluiden" ~ "vocal",
      TRUE ~ modality
    )
  ) %>%
  rename(participant_dyad = participant) %>%
  rename(participant_ID = pcnID) %>%
  rename(concept = English) %>%
  #select(-`Unnamed: 0`) %>%  # Remove the first column
  rename(stimulus = word)

# Reorder the columns in the specified order
df <- df %>%
  select(trial_order, trial_type, 
         dyad, participant_dyad, participant_ID, exp_part, modality, 
         expressibility_dutch, concept, correction,
         guess_binary, cosine_similarity, stimulus, answer, 
         SemanticSubcat, sessionID)

# Only keep target trials
df <- df %>%
  filter(trial_type == "target")%>%
  select(-`trial_type`) # Remove trial_type columns

```

## Exclude data points

We will remove productions in which the producers did not adhere with the modality condition (e.g., produced a gesture in the vocalization condition). The amount of excluded datapoints will be reported for each modality Any additional unforeseen exclusions will be reported.

```{r}
# exclude here (make to NA)
```

Adapt this code below to calculate NAs.

```{r calculate NAs, eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
# Columns to process
columns_to_process <- c(
  "duration", "duration_noSilence", 
)

# Ensure columns to process are numeric
columns_to_process <- columns_to_process[columns_to_process %in% names(data_prepost)]
columns_to_process <- columns_to_process[sapply(data_prepost[columns_to_process], is.numeric)]

# Function to calculate raw number and proportion of NAs
calculate_na_stats <- function(df, columns, group_column) {
  # Total NA stats
  total_na_counts <- colSums(is.na(df[, columns]))
  total_rows <- nrow(df)
  total_proportions <- total_na_counts / total_rows * 100
  
  # Initialize a data frame for results
  result_df <- data.frame(Variable = columns)
  
  # Calculate NA stats for each group
  unique_groups <- unique(df[[group_column]])
  for (group in unique_groups) {
    group_data <- df[df[[group_column]] == group, ]
    group_na_counts <- colSums(is.na(group_data[, columns]))
    group_total_rows <- nrow(group_data)
    group_proportions <- group_na_counts / group_total_rows * 100
    
    # Add group-specific NA counts and proportions in "count / proportion%" format
    result_df[[paste0(group, "_NA")]] <- paste0(
      group_na_counts, " / ", round(group_proportions, 2), "%"
    )
  }
  
  # Add total NA stats in "count / proportion%" format
  result_df[["Total_NA"]] <- paste0(
    total_na_counts, " / ", round(total_proportions, 2), "%"
  )
  
  return(result_df)
}

# Calculate NA stats
na_stats <- calculate_na_stats(data_prepost, columns_to_process, "language")

# Print the results
print(na_stats_before)
```


# Descriptive statistics

How many dyads?

```{r}
length(unique(df$dyad))
```

One dyad withdrew the consent, one dyad data still to be solved.

How many participants?

```{r}
length(unique(df$participant_ID))
```

How many concepts?

```{r}
length(unique(df$concept))

length(unique(df$stimulus))
```

How many productions in total?

```{r}
nrow(df)
```

How many productions are there per modality?

```{r}
df %>%
  group_by(modality) %>%
  summarise(frequency = n()) %>%
  arrange(desc(frequency)) %>% 
  print(n = 100)
```

How many productions are there per experiment part?

```{r}
df %>%
  group_by(exp_part) %>%
  summarise(frequency = n()) %>%
  arrange(desc(frequency)) %>% 
  print(n = 100)
```

How many productions are there per modality within experiment part?

```{r}
df %>%
  group_by(exp_part, modality) %>%
  summarise(frequency = n(), .groups = "drop") %>%  # Calculate frequency for each concept and modality
  pivot_wider(names_from = modality, values_from = frequency, names_prefix = "modality_") %>%
  #arrange(desc(modality_combined), desc(modality_gesture), desc(modality_vocal)) %>%  # Sort by modality frequencies
  print(n = 100)
```

How many productions are there per concept?

```{r}
df %>%
  group_by(concept) %>%
  summarise(frequency = n()) %>%
  arrange(desc(frequency)) %>% 
  print(n = 100)
```

How many productions per concept within each modality?

```{r}
df %>%
  group_by(concept, modality) %>%
  summarise(frequency = n(), .groups = "drop") %>%  # Calculate frequency for each concept and modality
  pivot_wider(names_from = modality, values_from = frequency, names_prefix = "modality_") %>%
  arrange(desc(modality_combined), desc(modality_gesture), desc(modality_vocal)) %>%  # Sort by modality frequencies
  print(n = 100)
```

How many productions per concept within the experiment parts?

```{r}
df %>%
  group_by(concept, exp_part) %>%
  summarise(frequency = n(), .groups = "drop") %>%  # Calculate frequency for each exp_part
  pivot_wider(names_from = exp_part, values_from = frequency, names_prefix = "frequency_part") %>%
  arrange(desc(frequency_part1), desc(frequency_part2)) %>%
  print(n = 100)
```

How many productions per concept within the experiment part and
modality?

```{r}
counts_exp_modality <- df %>%
  group_by(concept, exp_part, modality) %>%  # Group by concept, experiment part, and modality
  summarise(frequency = n(), .groups = "drop") %>%  # Calculate the frequency for each group
  pivot_wider(names_from = c(modality, exp_part), 
              values_from = frequency, 
              names_sep = "_") %>%  # Create modality_part_1 and modality_part_2 column names
  arrange(concept)  # Sort by concept for readability

counts_exp_modality

write.csv(counts_exp_modality, paste0(dataset, "counts_exp_modality.csv"), row.names = FALSE)
```

Plot productions per concept within each modality and experiment part.

```{r}
# For experiment part 1
df %>%
  filter(exp_part == 1) %>%  # Filter for experiment part 1
  group_by(concept, modality) %>%
  summarise(frequency = n(), .groups = "drop") %>%  # Calculate frequency for each concept and modality
  ggplot(aes(x = concept, y = frequency, fill = modality)) +  # Set up the plot
  geom_bar(stat = "identity", position = "stack") +  # Use stacked bars to show counts
  scale_fill_manual(values = colorBlindBlack8[1:3]) +  # Use first 3 colors from colorBlindBlack8 for modalities
  labs(
    x = "Concept",
    y = "Frequency (experiment part 1)",
    fill = "Modality"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),  # Rotate x-axis labels for readability
    text = element_text(size = 14)
  ) +
  coord_flip()  # Flip coordinates to make the plot more readable

ggsave(paste0(plots, "count_across_modalities_part1.png"), plot = last_plot(), width = 8, height = 10, dpi = 300)

# For experiment part 2
df %>%
  filter(exp_part == 2) %>%  # Filter for experiment part 2
  group_by(concept, modality) %>%
  summarise(frequency = n(), .groups = "drop") %>%  # Calculate frequency for each concept and modality
  ggplot(aes(x = concept, y = frequency, fill = modality)) +  # Set up the plot
  geom_bar(stat = "identity", position = "stack") +  # Use stacked bars to show counts
  scale_fill_manual(values = colorBlindBlack8[1:3]) +  # Use first 3 colors from colorBlindBlack8 for modalities
  labs(
    x = "Concept",
    y = "Frequency (experiment part 2)",
    fill = "Modality"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),  # Rotate x-axis labels for readability
    text = element_text(size = 14)
  ) +
  coord_flip()  # Flip coordinates to make the plot more readable

ggsave(paste0(plots, "count_across_modalities_part2.png"), plot = last_plot(), width = 8, height = 10, dpi = 300)
```

Let us visualize the proportion of modalities for each concept, only
based on second half of the experiment. This will show us where people
needed more repetitions.

```{r}
# For experiment part 1
ggplot(df %>%
         filter(exp_part == 1) %>%
         group_by(concept, modality) %>%
         summarise(frequency = n(), .groups = "drop") %>%
         group_by(concept) %>%
         mutate(total = sum(frequency), proportion = frequency / total) %>%
         ungroup(), aes(x = concept, y = proportion, fill = modality)) +
  geom_bar(stat = "identity") +  # Create a stacked bar plot
  scale_fill_manual(values = colorBlindBlack8[1:3]) +  # Use the first 3 colors from colorBlindBlack8
  labs(
    x = "Concept",
    y = "Proportion of frequency (experiment part 1)",
    fill = "Modality"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),  # Rotate x-axis labels for better readability
    text = element_text(size = 14)
  ) +
  coord_flip()  # Flip coordinates for better visibility of concept names

ggsave(paste0(plots, "proportion_across_modalities_part1.png"), plot = last_plot(), width = 8, height = 10, dpi = 300)

# For experimentpart 2
ggplot(df %>%
         filter(exp_part == 2) %>%
         group_by(concept, modality) %>%
         summarise(frequency = n(), .groups = "drop") %>%
         group_by(concept) %>%
         mutate(total = sum(frequency), proportion = frequency / total) %>%
         ungroup(), aes(x = concept, y = proportion, fill = modality)) +
  geom_bar(stat = "identity") +  # Create a stacked bar plot
  scale_fill_manual(values = colorBlindBlack8[1:3]) +  # Use the first 3 colors from colorBlindBlack8
  labs(
    x = "Concept",
    y = "Proportion of frequency (experiment part 2)",
    fill = "Modality"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),  # Rotate x-axis labels for better readability
    text = element_text(size = 14)
  ) +
  coord_flip()  # Flip coordinates for better visibility of concept names

ggsave(paste0(plots, "proportion_across_modalities_part2.png"), plot = last_plot(), width = 8, height = 10, dpi = 300)

```

What is the performance of each dyad? We only look at binary guessing.

```{r}
df %>%
  group_by(dyad) %>%
  summarise(
    total_trials = n(),  # Total number of rows per dyad
    total_guesses = sum(guess_binary == 1),  # Number of guesses where guess_binary == 1
    perf_dyad = (total_guesses / total_trials) * 100  # Percentage of correct guesses
  ) %>%
  arrange(desc(perf_dyad)) %>%  # Optional: sort by performance
  print(n = 100)
```

What is the performance of each participant within the dyad? We only
look at binary guessing.

```{r}
df %>%
  group_by(dyad, participant_dyad) %>%
  summarise(
    total_trials = n(),  # Total number of rows per dyad
    total_guesses = sum(guess_binary == 1),  # Number of guesses where guess_binary == 1
    perf_participant = (total_guesses / total_trials) * 100  # Percentage of correct guesses
  ) %>%
  arrange(desc(perf_participant)) %>%  # Optional: sort by performance
  print(n = 150)
```

### Hypothesis 1: Expressibility vs. guessability

*The higher the expressibility rating of the concept for the modality in
which the concept is produced, the higher the guessability will be.*

Expressibility and binary guessability?

```{r}
df %>%
  group_by(guess_binary) %>%
  summarise(
    mean_expressibility = mean(expressibility_dutch, na.rm = TRUE),
    sd_expressibility = sd(expressibility_dutch, na.rm = TRUE),
    min_expressibility = min(expressibility_dutch, na.rm = TRUE),
    max_expressibility = max(expressibility_dutch, na.rm = TRUE),
    median_expressibility = median(expressibility_dutch, na.rm = TRUE),
    n = n()
  )
```

Let's visualize it.

```{r}
ggplot(df, aes(x = expressibility_dutch, y = factor(guess_binary), fill = factor(guess_binary), color = factor(guess_binary))) +
  # Adding the slabinterval using stat_halfeye
  ggdist::stat_halfeye(
    aes(fill = factor(guess_binary), linewidth = 2),
    side = "left",  # Slabinterval on the left side
    #slab_color = NA,  # Remove outline for the slab
    interval_size = 1.2,  # Adjust interval thickness
    point_interval = mean_qi,  # Add mean and credible interval
    alpha = 0.5,
    size = 5
    #color = NA
  ) +
  # Adding geom_boxplot for the boxplot representation
  geom_boxplot(
    fill = "white",
    width = 0.10,
    lwd = 1,
    outlier.shape = NA,
    alpha = 0.5,
    position = position_nudge(y = 0.15)  # Slightly move the boxplot up to avoid overlap
  ) +
  # Adding stat_summary for the median point
  stat_summary(
    fun = mean,
    geom = "point",
    color = colorBlindBlack8[6],
    size = 3,
    position = position_nudge(y = 0.15)
  ) +
  # Customizing the colors
  scale_fill_manual(values = c("0" = colorBlindBlack8[1], "1" = colorBlindBlack8[2])) +
  scale_color_manual(values = c("0" = colorBlindBlack8[1], "1" = colorBlindBlack8[2])) +
  scale_y_discrete(labels = c("incorrect", "correct")) +  # Change x-axis labels
  coord_flip() +  # Flip the axes to match the orientation
  theme_minimal() +
  theme(
    legend.position = "none",  # Remove legend for simplicity
    plot.title = element_text(hjust = 0.5),  # Center-align the title
    axis.title.x = element_text(vjust = -0.5),  # Adjust x-axis label position
    axis.title.y = element_text(vjust = 1.5),   # Adjust y-axis label position
    text = element_text(size = 18)  # Increase font size for better readability
  ) +
  labs(
    y = "Guess",
    x = "Expressibility",
    fill = "Guess"
  )

ggsave(paste0(plots, "H1_expressibility_guessBinary.png"), plot = last_plot(), width = 6, height = 5, dpi = 300)
```

Expressibility and cosine similarity?

```{r}
# Calculate correlation coefficient
cor(df$expressibility_dutch, df$cosine_similarity, use = "complete.obs")
correlationBF(df$expressibility_dutch, df$cosine_similarity)
```

The **correlation coefficient** of **0.5176** suggests a **moderate to
strong positive correlation** between `expressibility_dutch` and
`cosine_similarity`.

The Bayes Factor indicates **extremely strong evidence in favor of a
non-zero correlation**, with a Bayes Factor of **2.035279e+531**. This
suggests that the correlation between `expressibility_dutch` and
`cosine_similarity` is extremely likely and the null hypothesis (no
correlation) can be rejected with very high confidence.

```{r}
# Scatter plot with correlation coefficient in the title
ggplot(df, aes(x = expressibility_dutch, y = cosine_similarity)) +
  geom_point(color = colorBlindBlack8[1], alpha = 0.5) +  # Set alpha for points
  geom_smooth(method = "lm", se = TRUE, color = colorBlindBlack8[2], size = 2) +  # Set thickness of lm line and add error bars (se = TRUE)
  scale_color_manual(
    values = colorBlindBlack8[2]
  ) +  # Rename cosine_similarity in the legend
  labs(
    x = "Expressibility",
    y = "Cosine similarity"
  ) +
  theme_minimal()
```

To better visualize the relationship let us calculate the average
`cosine_similarity` for each unique `expressibility_dutch` value and
create a plot where:

-   **Averaged points** are plotted on the graph.

-   The size of the dots represents the number of original observations
    contributing to each averaged point.

-   This will make it easier to see whether the relationship between
    `expressibility_dutch` and `cosine_similarity` is linear on average.

```{r}
df %>%
  group_by(expressibility_dutch) %>%
  summarise(
    mean_cosine_similarity = mean(cosine_similarity, na.rm = TRUE),  # Mean cosine similarity
    n = n()  # Count of data points for each unique x value
  ) %>%
  ggplot(aes(x = expressibility_dutch, y = mean_cosine_similarity, size = n)) +
  geom_point(color = colorBlindBlack8[1], alpha = 0.5) +  # Scatterplot with size mapped to n
  geom_smooth(method = "lm", se = TRUE, color = colorBlindBlack8[2], size = 1.5) +  # Linear regression line with error bars
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 20),  # Center-align and size of plot title
    axis.title.x = element_text(vjust = -0.5, size = 18),  # Adjust x-axis label position and size
    axis.title.y = element_text(vjust = 1.5, size = 18),   # Adjust y-axis label position and size
    axis.text.x = element_text(size = 14),  # Set size of x-axis text
    axis.text.y = element_text(size = 14),  # Set size of y-axis text
    legend.title = element_text(size = 16),  # Set size of legend title
    legend.text = element_text(size = 14),  # Set size of legend text
    text = element_text(size = 18)  # Increase general font size for better readability
  ) +
  labs(
    x = "Expressibility",
    y = "Mean cosine similarity",
    size = "Number of data points"
  )

ggsave(paste0(plots, "H1_expressibility_guessSimilarity.png"), plot = last_plot(), width = 8, height = 5, dpi = 300)
```

### Hypothesis 2: Expressibility vs. repetitions

*The higher the expressibility rating of the concept for the modality in
which the concept is produced, the fewer repetitions there will be.*

Calculate correlation between expressibility and correction

```{r}
df_part2 <- df %>%
  filter(exp_part == 2)

# Calculate correlation coefficient
cor(df_part2$expressibility_dutch, df_part2$correction, use = "complete.obs")
correlationBF(df_part2$expressibility_dutch, df_part2$correction)
```

-   The **Pearson correlation** of **-0.256** indicates a **weak negative
    relationship** between **expressibility** and **correction**,
    meaning that higher expressibility ratings tend to be associated
    with fewer repetitions.

-   The **Bayesian analysis** strongly supports this observation,
    providing **strong evidence for a non-zero correlation** between the
    two variables, which reinforces the weak correlation observed
    through Pearson’s method.

-   Even though the correlation is weak, the Bayesian evidence suggests
    a meaningful relationship between expressibility and the number of
    repetitions, meaning that we can expect some relationship between
    these two variables.

The **weak negative correlation** suggests that more **expressible
concepts** may be corrected fewer times, although the relationship isn't
very strong.


```{r}
df %>%
  filter(exp_part == 2) %>%
  group_by(expressibility_dutch) %>%
  summarise(
    mean_correction = mean(correction, na.rm = TRUE),  # Mean cosine similarity
    n = n()  # Count of data points for each unique x value
  ) %>%
  ggplot(aes(x = expressibility_dutch, y = mean_correction, size = n)) +
  geom_point(color = colorBlindBlack8[1], alpha = 0.5) +  # Scatterplot with size mapped to n
  geom_smooth(method = "lm", se = TRUE, color = colorBlindBlack8[2], size = 1.5) +  # Linear regression line with error bars
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 20),  # Center-align and size of plot title
    axis.title.x = element_text(vjust = -0.5, size = 18),  # Adjust x-axis label position and size
    axis.title.y = element_text(vjust = 1.5, size = 18),   # Adjust y-axis label position and size
    axis.text.x = element_text(size = 14),  # Set size of x-axis text
    axis.text.y = element_text(size = 14),  # Set size of y-axis text
    legend.title = element_text(size = 16),  # Set size of legend title
    legend.text = element_text(size = 14),  # Set size of legend text
    text = element_text(size = 18)  # Increase general font size for better readability
  ) +
  labs(
    x = "Expressibility",
    y = "Mean correction",
    size = "Number of data points"
  )

ggsave(paste0(plots, "H2_expressibility_correctionContinuous.png"), plot = last_plot(), width = 8, height = 5, dpi = 300)
```

What if we do not treat correction as continuous but categorical?

```{r}
df %>%
  filter(exp_part == 2) %>%
  group_by(correction) %>%
  summarise(
    mean_expressibility = mean(expressibility_dutch, na.rm = TRUE),  # Mean expressibility rating
    sd_expressibility = sd(expressibility_dutch, na.rm = TRUE),  # Standard deviation of expressibility
    median_expressibility = median(expressibility_dutch, na.rm = TRUE),  # Median expressibility
    n = n()  # Number of data points in each correction group
  )
```

Let's visualize it.

```{r}
df %>%
  filter(exp_part == 2) %>%
  ggplot(aes(x = expressibility_dutch, y = factor(correction), fill = factor(correction), color = factor(correction))) +
    # Adding the slabinterval using stat_halfeye
    ggdist::stat_halfeye(
      aes(fill = factor(correction), linewidth = 2),
      side = "left",  # Slabinterval on the left side
      #slab_color = NA,  # Remove outline for the slab
      interval_size = 1.2,  # Adjust interval thickness
      point_interval = mean_qi,  # Add mean and credible interval
      alpha = 0.5,
      size = 5
      #color = NA
    ) +
    # Adding geom_boxplot for the boxplot representation
    geom_boxplot(
      fill = "white",
      width = 0.10,
      lwd = 1,
      outlier.shape = NA,
      alpha = 0.5,
      position = position_nudge(y = 0.15)  # Slightly move the boxplot up to avoid overlap
    ) +
    # Adding stat_summary for the median point
    stat_summary(
      fun = mean,
      geom = "point",
      color = colorBlindBlack8[6],
      size = 3,
      position = position_nudge(y = 0.15)
    ) +
    # Customizing the colors
    scale_fill_manual(values = c("0" = colorBlindBlack8[1], "1" = colorBlindBlack8[2], "2" = colorBlindBlack8[3])) +
    scale_color_manual(values = c("0" = colorBlindBlack8[1], "1" = colorBlindBlack8[2], "2" = colorBlindBlack8[3])) +
    #scale_y_discrete(labels = c("incorrect", "correct")) +  # Change x-axis labels
    coord_flip() +  # Flip the axes to match the orientation
    theme_minimal() +
    theme(
      legend.position = "none",  # Remove legend for simplicity
      plot.title = element_text(hjust = 0.5),  # Center-align the title
      axis.title.x = element_text(vjust = -0.5),  # Adjust x-axis label position
      axis.title.y = element_text(vjust = 1.5),   # Adjust y-axis label position
      text = element_text(size = 18)  # Increase font size for better readability
    ) +
    labs(
      y = "Correction",
      x = "Expressibility",
      fill = "Correction"
    )

ggsave(paste0(plots, "H2_expressibility_correctionBinary.png"), plot = last_plot(), width = 6, height = 5, dpi = 300)
```

Just for exploration: modality mean expressibility and repetitions.

```{r}
df %>%
  filter(exp_part == 2) %>%
  group_by(modality) %>%
  summarise(
    mean_expressibility = mean(expressibility_dutch, na.rm = TRUE),  # Mean expressibility rating
    sd_expressibility = sd(expressibility_dutch, na.rm = TRUE),  # Standard deviation of expressibility
    mean_correction = mean(correction, na.rm = TRUE),  # Mean correction value (interpreted continuously)
    sd_correction = sd(correction, na.rm = TRUE),  # Standard deviation of correction
    cor_expressibility_correction = cor(expressibility_dutch, correction, use = "complete.obs")  # Correlation between expressibility and correction
  )
```


```{r}
df %>%
  filter(exp_part == 2) %>%
  ggplot(aes(x = factor(correction), fill = factor(correction))) +
  geom_bar(stat = "count", position = "dodge") +  # Count occurrences of each correction value
  facet_wrap(~ modality, scales = "free_y") +  # Facet by modality to show counts for each modality
  scale_fill_manual(values = c("0" = colorBlindBlack8[1], "1" = colorBlindBlack8[2], "2" = colorBlindBlack8[3])) +  # Custom colors for correction values
  labs(
    x = "Correction",
    y = "Frequency"
    #fill = "Repetition Number",
  ) +
  guides(fill = "none") +  # Remove the fill legend
  theme_minimal() +
  theme(
    text = element_text(size = 14),  # Increase text size for readability
    axis.title.x = element_text(vjust = -0.5),  # Adjust x-axis title position
    axis.title.y = element_text(vjust = 1.5)   # Adjust y-axis title position
  )

ggsave(paste0(plots, "corrections_across_modalities.png"), plot = last_plot(), width = 6, height = 4, dpi = 300)
```

### Hypothesis 3: Guessability vs. experiment part

*Guessability is higher when there is feedback between a producer and a
guesser (i.e., in the second half of the experiment, where the guesser
knows if they answered correctly, and the producer knows what the
guesser answered).*

#### All from part 2

Experiment parts and binary guessability

```{r}
df %>%
  group_by(exp_part) %>%
  summarise(
    total_trials = n(),  # Total number of rows for this experiment part
    total_guesses = sum(guess_binary == 1),  # Total successful guesses for this experiment part
    overall_performance = (total_guesses / total_trials) * 100  # Performance percentage
  ) %>%
  arrange(exp_part)  # Optional: Sort by experiment part
```

```{r}
ggplot(df, aes(x = factor(exp_part), y = guess_binary, fill = factor(exp_part))) +
  stat_summary(fun = "mean", geom = "bar", color = "black", alpha = 0.7) +  # Calculate mean for guess_binary (performance)
  stat_summary(fun.data = "mean_cl_normal", geom = "errorbar", width = 0.2) +  # Add error bars (95% CI)
  labs(
    x = "Experiment part", 
    y = "Guessability",
  ) +
  scale_fill_manual(values = c("1" = colorBlindBlack8[1], "2" = colorBlindBlack8[2])) + 
  guides(fill = "none") +  # Remove the fill legend
  scale_y_continuous(breaks = seq(0, 1, by = 0.05),
                     limits = c(0,1)) +
  theme_minimal() +
  theme(
    text = element_text(size = 14),  # Increase text size for readability
    axis.title.x = element_text(vjust = -0.5),  # Adjust x-axis title position
    axis.title.y = element_text(vjust = 1.5)   # Adjust y-axis title position
  )

ggsave(paste0(plots, "H3_guessBinary_all.png"), plot = last_plot(), width = 6, height = 6, dpi = 300)
```

Experiment parts and cosine similarity

```{r}
df %>%
  group_by(exp_part) %>%
  summarise(
    avg_cosine_similarity = mean(cosine_similarity, na.rm = TRUE),  # Mean cosine similarity
    sd_cosine_similarity = sd(cosine_similarity, na.rm = TRUE),    # Standard deviation
    total_trials = n()  # Total number of trials for reference
  ) %>%
  arrange(exp_part)  # Optional: Sort by experiment part

```

```{r}
ggplot(df, aes(x = factor(exp_part), y = cosine_similarity, fill = factor(exp_part))) +
  stat_summary(fun = "mean", geom = "bar", color = "black", alpha = 0.7) +  
  stat_summary(fun.data = "mean_cl_normal", geom = "errorbar", width = 0.2) +  # Add error bars (95% CI)
  labs(
    x = "Experiment part", 
    y = "Cosine similarity",
  ) +
  scale_fill_manual(values = c("1" = colorBlindBlack8[1], "2" = colorBlindBlack8[2])) + 
  guides(fill = "none") +  # Remove the fill legend
  scale_y_continuous(breaks = seq(0, 1, by = 0.05),
                     limits = c(0,1)) +
  theme_minimal() +
  theme(
    text = element_text(size = 14),  # Increase text size for readability
    axis.title.x = element_text(vjust = -0.5),  # Adjust x-axis title position
    axis.title.y = element_text(vjust = 1.5)   # Adjust y-axis title position
  )

ggsave(paste0(plots, "H3_guessSimilarity_all.png"), plot = last_plot(), width = 6, height = 6, dpi = 300)

```

#### Only first from part 2

In part 1, participants only had one shot at trying. In part 2, they had up to three trials, so 2 corrections. Let us compare only the first production from the second part to the production from part 1.

Start with binary guess.

```{r}
df %>%
  filter(exp_part == 1 | (exp_part == 2 & correction == 0)) %>% 
  group_by(exp_part) %>%
  summarise(
    total_trials = n(),
    total_guesses = sum(guess_binary == 1),
    overall_performance = (total_guesses / total_trials) * 100 
  ) %>%
  arrange(exp_part)
```

```{r}
df %>%
  filter(exp_part == 1 | (exp_part == 2 & correction == 0)) %>% 
  ggplot(aes(x = factor(exp_part), y = guess_binary, fill = factor(exp_part))) +
    stat_summary(fun = "mean", geom = "bar", color = "black", alpha = 0.7) +  # Calculate mean for guess_binary (performance)
    stat_summary(fun.data = "mean_cl_normal", geom = "errorbar", width = 0.2) +  # Add error bars (95% CI)
    labs(
      x = "Experiment part", 
      y = "Guessability",
    ) +
    scale_fill_manual(values = c("1" = colorBlindBlack8[1], "2" = colorBlindBlack8[2])) + 
    guides(fill = "none") +  # Remove the fill legend
    scale_y_continuous(breaks = seq(0, 1, by = 0.05),
                       limits = c(0,1)) +
    theme_minimal() +
  theme(
    text = element_text(size = 14),  # Increase text size for readability
    axis.title.x = element_text(vjust = -0.5),  # Adjust x-axis title position
    axis.title.y = element_text(vjust = 1.5)   # Adjust y-axis title position
  )

ggsave(paste0(plots, "H3_guessBinary_first.png"), plot = last_plot(), width = 6, height = 6, dpi = 300)
```

Now to cosine similarity.


Experiment parts and cosine similarity

```{r}
df %>%
  filter(exp_part == 1 | (exp_part == 2 & correction == 0)) %>% 
  group_by(exp_part) %>%
  summarise(
    avg_cosine_similarity = mean(cosine_similarity, na.rm = TRUE), 
    sd_cosine_similarity = sd(cosine_similarity, na.rm = TRUE), 
    total_trials = n()
  ) %>%
  arrange(exp_part)

```

```{r}
df %>%
  filter(exp_part == 1 | (exp_part == 2 & correction == 0)) %>% 
  ggplot(aes(x = factor(exp_part), y = cosine_similarity, fill = factor(exp_part))) +
    stat_summary(fun = "mean", geom = "bar", color = "black", alpha = 0.7) +  
    stat_summary(fun.data = "mean_cl_normal", geom = "errorbar", width = 0.2) +  # Add error bars (95% CI)
    labs(
      x = "Experiment part", 
      y = "Cosine similarity",
    ) +
    scale_fill_manual(values = c("1" = colorBlindBlack8[1], "2" = colorBlindBlack8[2])) + 
    guides(fill = "none") +  # Remove the fill legend
    scale_y_continuous(breaks = seq(0, 1, by = 0.05),
                       limits = c(0,1)) +
    theme_minimal() +
    theme(
      text = element_text(size = 14),  # Increase text size for readability
      axis.title.x = element_text(vjust = -0.5),  # Adjust x-axis title position
      axis.title.y = element_text(vjust = 1.5)   # Adjust y-axis title position
    )

ggsave(paste0(plots, "H3_guessSimilarity_first.png"), plot = last_plot(), width = 6, height = 6, dpi = 300)

```

Sarka's plot

```{r}
# talk to Sarka next week what she meant

df %>%
  filter(exp_part == 1 | (exp_part == 2 & correction == 0)) %>% 
  ggplot(aes(x = factor(exp_part), y = cosine_similarity, fill = factor(exp_part))) +
    stat_summary(fun = "mean", geom = "bar", color = "black", alpha = 0.7) +  
    stat_summary(fun.data = "mean_cl_normal", geom = "errorbar", width = 0.2) +  # Add error bars (95% CI)
    labs(
      x = "Experiment part", 
      y = "Cosine similarity",
    ) +
    scale_fill_manual(values = c("1" = colorBlindBlack8[1], "2" = colorBlindBlack8[2])) + 
    guides(fill = "none") +  # Remove the fill legend
    scale_y_continuous(breaks = seq(0, 1, by = 0.05),
                       limits = c(0,1)) +
    theme_minimal() +
    theme(
      text = element_text(size = 14),  # Increase text size for readability
      axis.title.x = element_text(vjust = -0.5),  # Adjust x-axis title position
      axis.title.y = element_text(vjust = 1.5)   # Adjust y-axis title position
    )
```


### Hypothesis 4: Guessability vs. modality

*Guessability will differ by modality; the order from highest to lowest
will be: combined \> gesture \> vocalization.*

Modalities and binary guessability.

```{r}
df %>%
  group_by(modality) %>%
  summarise(
    total_trials = n(),  # Number of trials for each modality
    total_guesses = sum(guess_binary == 1),  # Number of correct guesses
    perf_modality = (total_guesses / total_trials) * 100  # Performance as percentage
  ) %>%
  arrange(desc(perf_modality))
```

Visualize the binary guessability across modalities.

```{r}
ggplot(df, aes(x = modality, y = guess_binary, fill = modality)) +
  stat_summary(fun = "mean", geom = "bar", color = "black", alpha = 0.7) +  # Calculate mean for guess_binary (performance)
  stat_summary(fun.data = "mean_cl_normal", geom = "errorbar", width = 0.2) +  # Add error bars (95% CI)
  labs(
    x = "Modality", 
    y = "Guessability",
  ) +
  scale_fill_manual(values = c("combined" = colorBlindBlack8[1], "gesture" = colorBlindBlack8[2], "vocal" = colorBlindBlack8[3])) +  # Customize colors
  guides(fill = "none") +  # Remove the fill legend
  scale_y_continuous(breaks = seq(0, 1, by = 0.05),
                     limits = c(0,1)) +
  theme_minimal() +
    theme(
      text = element_text(size = 14),  # Increase text size for readability
      axis.title.x = element_text(vjust = -0.5),  # Adjust x-axis title position
      axis.title.y = element_text(vjust = 1.5)   # Adjust y-axis title position
    )

ggsave(paste0(plots, "H4_modality_guessBinary.png"), plot = last_plot(), width = 6, height = 6, dpi = 300)
```

Modalities and cosine similarity

```{r}
df %>%
  group_by(modality) %>%
  summarise(
    total_trials = n(),  # Number of trials for each modality
    mean_cosine_similarity = mean(cosine_similarity, na.rm = TRUE),  # Mean cosine similarity
    sd_cosine_similarity = sd(cosine_similarity, na.rm = TRUE),  # Standard deviation of cosine similarity
    perf_modality = (mean_cosine_similarity) * 100  # Performance as percentage
  ) %>%
  arrange(desc(perf_modality))
```

Visualize the cosine similarity across modalities

```{r}
ggplot(df, aes(x = modality, y = cosine_similarity, fill = modality)) +
  stat_summary(fun = "mean", geom = "bar", color = "black", alpha = 0.7) +  # Calculate mean
  stat_summary(fun.data = "mean_cl_normal", geom = "errorbar", width = 0.2) +  # Add error bars (95% CI)
  labs(
    x = "Modality", 
    y = "Cosine similarity",
  ) +
  scale_fill_manual(values = c("combined" = colorBlindBlack8[1], "gesture" = colorBlindBlack8[2], "vocal" = colorBlindBlack8[3])) +  # Customize colors
  guides(fill = "none") +  # Remove the fill legend
  scale_y_continuous(breaks = seq(0, 1, by = 0.05),
                     limits = c(0,1)) +
  theme_minimal()  +
    theme(
      text = element_text(size = 14),  # Increase text size for readability
      axis.title.x = element_text(vjust = -0.5),  # Adjust x-axis title position
      axis.title.y = element_text(vjust = 1.5)   # Adjust y-axis title position
    )

ggsave(paste0(plots, "H4_modality_guessSimilarity.png"), plot = last_plot(), width = 6, height = 6, dpi = 300)
```

# Export data frame

```{r}
write.csv(df, paste0(dataset, "df.csv"), row.names = FALSE)
```


# Session info

```{r echo=TRUE, message=FALSE, warning=FALSE}
sessionInfo()
```
