## 72 out of 84
df_worst %>%
group_by(concept) %>%
summarise(frequency = n()) %>%
arrange(desc(frequency)) %>%
print(n = 100)
View(df_best)
# Best of best ----
# Identify the best-performing dyad and participant for each unique concept
best_of_best <- df_best %>%
group_by(concept) %>%  # Group by unique concepts
filter(
perf_dyad == max(perf_dyad)  # Retain rows with the best-performing dyad
) %>%
filter(
perf_participant_ID == max(perf_participant_ID)
) %>%
ungroup()
# Worst of worst ----
# Identify the worst-performing dyad and participant for each unique concept
worst_of_worst <- df_worst %>%
group_by(concept) %>%  # Group by unique concepts
filter(
cosine_similarity == min(cosine_similarity, na.rm = TRUE)  # Retain rows with the lowest cosine similarity
) %>%
filter(
perf_dyad == min(perf_dyad)  # Among those, retain rows with the worst-performing dyad
) %>%
filter(
perf_participant_ID == min(perf_participant_ID)
) %>%
ungroup()
# Check repetitions
best_of_best %>%
group_by(concept) %>%
summarise(row_count = n()) %>%
mutate(type = ifelse(row_count > 1, "repeated", "single")) %>%
summarise(
total_repeated = sum(type == "repeated"),
total_single = sum(type == "single")
)
worst_of_worst %>%
group_by(concept) %>%
summarise(row_count = n()) %>%
mutate(type = ifelse(row_count > 1, "repeated", "single")) %>%
summarise(
total_repeated = sum(type == "repeated"),
total_single = sum(type == "single") )
View(best_of_best)
setdiff(unique(trimws(tolower(df$concept))), unique(trimws(tolower(df_best$concept))))
# Check repetitions
best_of_best %>%
group_by(concept) %>%
summarise(row_count = n()) %>%
mutate(type = ifelse(row_count > 1, "repeated", "single")) %>%
summarise(
total_repeated = sum(type == "repeated"),
total_single = sum(type == "single")
)
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2: source setup
########## folders ##########
library(here)
parentfolder <- dirname(getwd())
rawdata       <- paste0(parentfolder, '/rawdata/');
dataset       <- paste0(parentfolder, '/dataset/');
models        <- paste0(parentfolder, '/models/');
plots         <- paste0(parentfolder, '/plots/');
scripts       <- paste0(parentfolder, '/scripts/');
########## source file ##########
#rmarkdown::render("1_descriptive.Rmd", envir = globalenv(), clean = FALSE)
#################### packages ####################
# Data Manipulation
library(tidyverse);
# Plotting
library(corrplot);
library(cowplot);
library(ggdist);
# Bayesian
library(brms);
library(cmdstanr);
library(emmeans);
library(posterior);
library(tidybayes);
theme_set(theme_tidybayes() + panel_border());
# use all available cores for parallel computing
options(mc.cores = parallel::detectCores());
colorBlindBlack8  <- c("#000000", "#E69F00", "#56B4E9", "#009E73",
"#F0E442", "#0072B2", "#D55E00", "#CC79A7")
# Chunk 3: read metadata
# Load data frame
df <- read_csv(paste0(dataset, "df.csv"))
# Load concept list
concepts <- read_excel(paste0(dataset, "conceptlist_info.xlsx"))
# Load expressibility German
expr_german <- read_csv(paste0(dataset, "expressibility_german.csv"))
# Load expressibility Dutch
expr_dutch <- read_csv(paste0(dataset, "expressibility_dutch.csv"))
View(expr_dutch)
View(expr_dutch)
library(here)
parentfolder <- dirname(getwd())
dataset       <- paste0(parentfolder, '/dataset/')
scripts       <- paste0(parentfolder, '/scripts/')
library(tidyverse) # includes readr, tidyr, dplyr, ggplot2
library(stringr)
library(readxl)
# Load data ----
df <- read_csv(paste0(dataset, "similarity_df_final.csv"))
# Load concept list
concepts <- read_excel(paste0(dataset, "conceptlist_info.xlsx"))
# Filter ----
# Modify the modality column, filter only multimodal and where sessionID ends with '1'
df <- df %>%
mutate(
modality = case_when(
modality == "combinatie" ~ "combined",
modality == "gebaren" ~ "gesture",
modality == "geluiden" ~ "vocal",
TRUE ~ modality
)
) %>%
filter(modality == "combined") %>%
filter(str_ends(sessionID, "1")) %>%
rename(participant_dyad = participant) %>%
rename(participant_ID = pcnID) %>%
rename(concept = English) %>%
select(-`...1`) %>%  # Remove the first column
rename(stimulus = word)
# Reorder the columns in the specified order
df <- df %>%
select(trial_order, trial_type,
dyad, participant_dyad, participant_ID, exp_part, modality,
expressibility_dutch, concept, correction,
guess_binary, cosine_similarity, stimulus, answer,
SemanticSubcat, sessionID)
# Only keep target trials
df <- df %>%
filter(trial_type == "target")%>%
select(-`trial_type`) # Remove trial_type columns
# Add guessing performance
## Calculate performance by dyad and add it as a new column
df <- df %>%
group_by(dyad) %>%
mutate(
perf_dyad = (sum(guess_binary == 1) / n()) * 100
) %>%
ungroup()
## Calculate performance by participant within dyad and add it as a new column
df <- df %>%
group_by(dyad, participant_dyad) %>%
mutate(
perf_participant_dyad = (sum(guess_binary == 1) / n()) * 100
) %>%
ungroup()
## Calculate performance by participant
df <- df %>%
group_by(participant_ID) %>%
mutate(
perf_participant_ID = (sum(guess_binary == 1) / n()) * 100
) %>%
ungroup()
# Sort by optimal and suboptimal
df_best <- df %>%
filter(guess_binary == 1)
df_worst <- df %>%
filter(guess_binary == 0)
# Frequencies ----
# Generate a frequency table for the 'concept' column
df_best %>%
group_by(concept) %>%
summarise(frequency = n()) %>%
arrange(desc(frequency)) %>%
print(n = 100)
## 72 out of 84
df_worst %>%
group_by(concept) %>%
summarise(frequency = n()) %>%
arrange(desc(frequency)) %>%
print(n = 100)
## 81 out of 84
# Best of best ----
# Identify the best-performing dyad and participant for each unique concept
best_of_best <- df_best %>%
group_by(concept) %>%  # Group by unique concepts
filter(
perf_dyad == max(perf_dyad)  # Retain rows with the best-performing dyad
) %>%
filter(
perf_participant_ID == max(perf_participant_ID)
) %>%
ungroup()
# Worst of worst ----
# Identify the worst-performing dyad and participant for each unique concept
worst_of_worst <- df_worst %>%
group_by(concept) %>%  # Group by unique concepts
filter(
cosine_similarity == min(cosine_similarity, na.rm = TRUE)  # Retain rows with the lowest cosine similarity
) %>%
filter(
perf_dyad == min(perf_dyad)  # Among those, retain rows with the worst-performing dyad
) %>%
filter(
perf_participant_ID == min(perf_participant_ID)
) %>%
ungroup()
# Check repetitions
best_of_best %>%
group_by(concept) %>%
summarise(row_count = n()) %>%
mutate(type = ifelse(row_count > 1, "repeated", "single")) %>%
summarise(
total_repeated = sum(type == "repeated"),
total_single = sum(type == "single")
)
setdiff(unique(trimws(tolower(df$concept))), unique(trimws(tolower(df_best$concept))))
worst_of_worst %>%
group_by(concept) %>%
summarise(row_count = n()) %>%
mutate(type = ifelse(row_count > 1, "repeated", "single")) %>%
summarise(
total_repeated = sum(type == "repeated"),
total_single = sum(type == "single") )
setdiff(unique(trimws(tolower(df$concept))), unique(trimws(tolower(df_worst$concept))))
View(best_of_best)
best_of_best
worst_of_worst
View(best_of_best)
library(here)
parentfolder <- dirname(getwd())
dataset       <- paste0(parentfolder, '/dataset/')
scripts       <- paste0(parentfolder, '/scripts/')
library(tidyverse) # includes readr, tidyr, dplyr, ggplot2
library(stringr)
library(readxl)
# Load data ----
df <- read_csv(paste0(dataset, "similarity_df_final.csv"))
# Load concept list
concepts <- read_excel(paste0(dataset, "conceptlist_info.xlsx"))
# Filter ----
# Modify the modality column, filter only multimodal and where sessionID ends with '1'
df <- df %>%
mutate(
modality = case_when(
modality == "combinatie" ~ "combined",
modality == "gebaren" ~ "gesture",
modality == "geluiden" ~ "vocal",
TRUE ~ modality
)
) %>%
filter(modality == "combined") %>%
filter(str_ends(sessionID, "1")) %>%
rename(participant_dyad = participant) %>%
rename(participant_ID = pcnID) %>%
rename(concept = English) %>%
select(-`...1`) %>%  # Remove the first column
rename(stimulus = word)
# Reorder the columns in the specified order
df <- df %>%
select(trial_order, trial_type,
dyad, participant_dyad, participant_ID, exp_part, modality,
expressibility_dutch, concept, correction,
guess_binary, cosine_similarity, stimulus, answer,
SemanticSubcat, sessionID)
# Only keep target trials
df <- df %>%
filter(trial_type == "target")%>%
select(-`trial_type`) # Remove trial_type columns
# Add guessing performance
## Calculate performance by dyad and add it as a new column
df <- df %>%
group_by(dyad) %>%
mutate(
perf_dyad = (sum(guess_binary == 1) / n()) * 100
) %>%
ungroup()
## Calculate performance by participant within dyad and add it as a new column
df <- df %>%
group_by(dyad, participant_dyad) %>%
mutate(
perf_participant_dyad = (sum(guess_binary == 1) / n()) * 100
) %>%
ungroup()
## Calculate performance by participant
df <- df %>%
group_by(participant_ID) %>%
mutate(
perf_participant_ID = (sum(guess_binary == 1) / n()) * 100
) %>%
ungroup()
# Calculate mean/median cosine similarity for each participant
df_best <- df_best %>%
group_by(participant_ID) %>%
mutate(
mean_cosine_similarity = mean(cosine_similarity, na.rm = TRUE),  # Replace with median() if needed
median_cosine_similarity = median(cosine_similarity, na.rm = TRUE)  # Optional: include both metrics
) %>%
ungroup()
# Calculate mean/median cosine similarity for each participant
df <- df %>%
group_by(participant_ID) %>%
mutate(
mean_cosine_similarity = mean(cosine_similarity, na.rm = TRUE),  # Replace with median() if needed
median_cosine_similarity = median(cosine_similarity, na.rm = TRUE)  # Optional: include both metrics
) %>%
ungroup()
# Sort by optimal and suboptimal
df_best <- df %>%
filter(guess_binary == 1)
df_worst <- df %>%
filter(guess_binary == 0)
# Frequencies ----
# Generate a frequency table for the 'concept' column
df_best %>%
group_by(concept) %>%
summarise(frequency = n()) %>%
arrange(desc(frequency)) %>%
print(n = 100)
## 72 out of 84
df_worst %>%
group_by(concept) %>%
summarise(frequency = n()) %>%
arrange(desc(frequency)) %>%
print(n = 100)
# Best of best ----
# Identify the best-performing dyad and participant for each unique concept
best_of_best <- df_best %>%
# Best of best ----
# Identify the best-performing dyad and participant for each unique concept
best_of_best <- df_best %>%
group_by(concept) %>%  # Group by unique concepts
filter(
perf_dyad == max(perf_dyad)  # Retain rows with the best-performing dyad
) %>%
filter(
perf_participant_ID == max(perf_participant_ID)
) %>%
filter(
mean_cosine_similarity == max(mean_cosine_similarity, na.rm = TRUE)
) %>%
ungroup()
View(best_of_best)
# Worst of worst ----
# Identify the worst-performing dyad and participant for each unique concept
worst_of_worst <- df_worst %>%
group_by(concept) %>%  # Group by unique concepts
filter(
cosine_similarity == min(cosine_similarity, na.rm = TRUE)  # Retain rows with the lowest cosine similarity
) %>%
filter(
perf_dyad == min(perf_dyad)  # Among those, retain rows with the worst-performing dyad
) %>%
filter(
perf_participant_ID == min(perf_participant_ID)
) %>%
ungroup()
# Check repetitions
best_of_best %>%
group_by(concept) %>%
summarise(row_count = n()) %>%
mutate(type = ifelse(row_count > 1, "repeated", "single")) %>%
summarise(
total_repeated = sum(type == "repeated"),
total_single = sum(type == "single")
)
setdiff(unique(trimws(tolower(df$concept))), unique(trimws(tolower(df_best$concept))))
worst_of_worst %>%
group_by(concept) %>%
summarise(row_count = n()) %>%
mutate(type = ifelse(row_count > 1, "repeated", "single")) %>%
summarise(
total_repeated = sum(type == "repeated"),
total_single = sum(type == "single") )
setdiff(unique(trimws(tolower(df$concept))), unique(trimws(tolower(df_best$concept))))
setdiff(unique(trimws(tolower(df$concept))), unique(trimws(tolower(df_worst$concept))))
# Find missing ----
# List of concepts missing from best_of_best
missing_from_best <- setdiff(unique(trimws(tolower(df$concept))), unique(trimws(tolower(df_best$concept))))
# Filter df for the missing concepts and find the highest cosine_similarity for each
missing_best_concepts <- df %>%
filter(trimws(tolower(concept)) %in% missing_from_best) %>%
group_by(concept) %>%
summarise(
highest_cosine_similarity = max(cosine_similarity, na.rm = TRUE),
best_row = list(filter(., cosine_similarity == max(cosine_similarity, na.rm = TRUE)))
) %>%
unnest(cols = best_row)
# Filter df for the missing concepts and extract rows with the highest cosine_similarity
missing_best_concepts <- df %>%
filter(trimws(tolower(concept)) %in% missing_from_best) %>%
group_by(concept) %>%
filter(cosine_similarity == max(cosine_similarity, na.rm = TRUE)) %>%
ungroup()
View(missing_best_concepts)
# Filter df for the missing concepts and extract rows with the highest cosine_similarity
missing_best_concepts <- df %>%
filter(trimws(tolower(concept)) %in% missing_from_best) %>%
group_by(concept) %>%
filter(cosine_similarity == max(cosine_similarity, na.rm = TRUE)) %>%
filter(
perf_dyad == max(perf_dyad)  # Retain rows with the best-performing dyad
) %>%
filter(
perf_participant_ID == max(perf_participant_ID)
) %>%
filter(
mean_cosine_similarity == max(mean_cosine_similarity, na.rm = TRUE)
) %>%
ungroup()
View(missing_best_concepts)
# List of concepts missing from worst_of_worst
missing_from_worst <- setdiff(unique(trimws(tolower(df$concept))), unique(trimws(tolower(df_worst$concept))))
# Filter df for the missing concepts and extract rows with the highest cosine_similarity
missing_worst_concepts <- df %>%
filter(trimws(tolower(concept)) %in% missing_from_worst) %>%
group_by(concept) %>%
filter(cosine_similarity == min(cosine_similarity, na.rm = TRUE)) %>%
filter(
perf_dyad == min(perf_dyad)  # Retain rows with the best-performing dyad
) %>%
filter(
perf_participant_ID == min(perf_participant_ID)
) %>%
filter(
mean_cosine_similarity == min(mean_cosine_similarity, na.rm = TRUE)
) %>%
ungroup()
# Combine best_of_best with missing_best_concepts
the_best <- bind_rows(best_of_best, missing_best_concepts)
write.csv(the_best, paste0(dataset, "the_best.csv"), row.names = FALSE)
# Combine worst_of_worst with missing_worst_concepts
the_worst <- bind_rows(worst_of_worst, missing_worst_concepts)
write.csv(the_worst, paste0(dataset, "the_worst.csv"), row.names = FALSE)
View(the_worst)
View(the_best)
View(the_worst)
View(the_best)
View(the_worst)
# Combine the_best and the_worst with the "optimality" column in one pipeline
final_combined <- bind_rows(
the_best %>% mutate(optimality = "best"),
the_worst %>% mutate(optimality = "worst")
)
View(final_combined)
# Calculate the difference in cosine_similarity between best and worst for each concept
best_worst_concept_comparison <- final_combined %>%
group_by(concept) %>%
summarise(
similarity_distance = max(cosine_similarity[optimality == "best"], na.rm = TRUE) -
max(cosine_similarity[optimality == "worst"], na.rm = TRUE)
) %>%
ungroup()
View(best_worst_concept_comparison)
# Calculate the difference in cosine_similarity between best and worst for each concept
best_worst_concept_comparison <- final_combined %>%
group_by(concept) %>%
summarise(
best_cosine_similarity = max(cosine_similarity[optimality == "best"], na.rm = TRUE),
worst_cosine_similarity = max(cosine_similarity[optimality == "worst"], na.rm = TRUE),
best_perf_dyad = max(perf_dyad[optimality == "best"], na.rm = TRUE),
worst_perf_dyad = max(perf_dyad[optimality == "worst"], na.rm = TRUE),
best_perf_participant_ID = max(perf_participant_ID[optimality == "best"], na.rm = TRUE),
worst_perf_participant_ID = max(perf_participant_ID[optimality == "worst"], na.rm = TRUE),
best_mean_cosine_similarity = max(mean_cosine_similarity[optimality == "best"], na.rm = TRUE),
worst_mean_cosine_similarity = max(mean_cosine_similarity[optimality == "worst"], na.rm = TRUE),
similarity_distance = best_cosine_similarity - worst_cosine_similarity
) %>%
ungroup()
View(best_worst_concept_comparison)
# Calculate the difference in cosine_similarity between best and worst for each concept
best_worst_concept_comparison <- final_combined %>%
group_by(concept) %>%
summarise(
similarity_distance = best_cosine_similarity - worst_cosine_similarity,
best_cosine_similarity = max(cosine_similarity[optimality == "best"], na.rm = TRUE),
worst_cosine_similarity = max(cosine_similarity[optimality == "worst"], na.rm = TRUE),
best_perf_dyad = max(perf_dyad[optimality == "best"], na.rm = TRUE),
worst_perf_dyad = max(perf_dyad[optimality == "worst"], na.rm = TRUE),
best_perf_participant_ID = max(perf_participant_ID[optimality == "best"], na.rm = TRUE),
worst_perf_participant_ID = max(perf_participant_ID[optimality == "worst"], na.rm = TRUE),
best_mean_cosine_similarity = max(mean_cosine_similarity[optimality == "best"], na.rm = TRUE),
worst_mean_cosine_similarity = max(mean_cosine_similarity[optimality == "worst"], na.rm = TRUE)
) %>%
ungroup()
# Calculate the difference in cosine_similarity between best and worst for each concept
best_worst_concept_comparison <- final_combined %>%
group_by(concept) %>%
summarise(
similarity_distance = max(cosine_similarity[optimality == "best"], na.rm = TRUE) -
max(cosine_similarity[optimality == "worst"], na.rm = TRUE),
best_cosine_similarity = max(cosine_similarity[optimality == "best"], na.rm = TRUE),
worst_cosine_similarity = max(cosine_similarity[optimality == "worst"], na.rm = TRUE),
best_perf_dyad = max(perf_dyad[optimality == "best"], na.rm = TRUE),
worst_perf_dyad = max(perf_dyad[optimality == "worst"], na.rm = TRUE),
best_perf_participant_ID = max(perf_participant_ID[optimality == "best"], na.rm = TRUE),
worst_perf_participant_ID = max(perf_participant_ID[optimality == "worst"], na.rm = TRUE),
best_mean_cosine_similarity = max(mean_cosine_similarity[optimality == "best"], na.rm = TRUE),
worst_mean_cosine_similarity = max(mean_cosine_similarity[optimality == "worst"], na.rm = TRUE)
) %>%
ungroup()
View(final_combined)
View(best_worst_concept_comparison)
View(best_of_best)
View(the_best)
View(the_worst)
unique(df_best$dyad)
length(unique(df_best$dyad))
length(unique(the_best$dyad))
length(unique(the_worst$dyad))
length(unique(the_worst$participant_ID))
length(unique(the_best$participant_ID))
