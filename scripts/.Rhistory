kfold_1_2 <- loo_compare(model1, model2, criterion="kfold", model_names=c(ifelse(!is.na(name1), name1, "model1"), ifelse(!is.na(name2), name2, "model2")));
} else
{
kfold_1_2 <- NA;
}
if( print_results )
{
cat(paste0("\nComparing models '",ifelse(!is.na(name1), name1, "model1"),"' and '",ifelse(!is.na(name2), name2, "model2"),"':\n\n"));
cat(paste0("\ndelta R^2 = ",sprintf("%.1f%%",100*R2_1_2),"\n\n"));
cat(bf_interpret_1_2,"\n\n");
cat("\nLOO:\n"); print(loo_1_2);
cat("\nWAIC:\n"); print(waic_1_2);
cat("\nKFOLD:\n"); print(kfold_1_2);
cat("\nModel weights (WAIC):\n"); print(mw_1_2);
cat("\n");
}
gc();
return (list("R2"=R2_1_2, "BF"=bf_1_2, "BF_interpretation"=bf_interpret_1_2, "LOO"=loo_1_2, "WAIC"=waic_1_2, "KFOLD"=kfold_1_2, "model_weights_WAIC"=mw_1_2));
}
# print model comparisons
.print.model.comparison <- function(a=NULL, a.names=NULL, b=NULL) # a is the anova and b is the Bayesian comparison (only one can be non-NULL), a.names are the mappings between the inner and user-friendly model names
{
# ANOVA:
if( !is.null(a) )
{
a <- as.data.frame(a);
if( !is.null(a.names) )
{
if( length(a.names) != nrow(a) || !all(names(a.names) %in% rownames(a)) )
{
stop("a.names do not correspond the anova model names!");
return (NULL);
}
rownames(a) <- a.names[rownames(a)];
}
i <- which.min(a$AIC);
s.a <- sprintf("%s %s %s: ΔAIC=%.1f, ΔBIC=%.1f",
rownames(a)[i],
ifelse((!is.na(a[2,"Pr(>Chisq)"]) && a[2,"Pr(>Chisq)"] <0.05) || (abs(a$AIC[1] - a$AIC[2]) > 3), ">", "≈"),
rownames(a)[3-i],
abs(a$AIC[1] - a$AIC[2]),
abs(a$BIC[1] - a$BIC[2]));
if( !is.na(a[2,"Pr(>Chisq)"]) )
{
s.a <- paste0(s.a,
sprintf(", *p*=%s", scinot(a[2,"Pr(>Chisq)"])));
}
# return value:
return (s.a);
}
# Bayesian comparison:
if( !is.null(b) )
{
s.b <- sprintf("BF: %s, ΔLOO(%s %s %s)=%.1f (%.1f), ΔWAIC(%s %s %s)=%.1f (%.1f), ΔKFOLD(%s %s %s)=%.1f (%.1f)",
# BF:
b$BF_interpretation,
# LOO:
rownames(b$LOO)[1],
ifelse(abs(b$LOO[1,1]-b$LOO[2,1]) < 4 || abs(b$LOO[1,1]-b$LOO[2,1]) < b$LOO[2,2], "≈", ifelse(abs(b$LOO[1,1]-b$LOO[2,1]) < 2*b$LOO[2,2], ">", ">>")),
rownames(b$LOO)[2],
abs(b$LOO[1,1]-b$LOO[2,1]), b$LOO[2,2],
# WAIC:
rownames(b$WAIC)[1],
ifelse(abs(b$WAIC[1,1]-b$WAIC[2,1]) < 4 || abs(b$WAIC[1,1]-b$WAIC[2,1]) < b$WAIC[2,2], "≈", ifelse(abs(b$WAIC[1,1]-b$WAIC[2,1]) < 2*b$WAIC[2,2], ">", ">>")),
rownames(b$WAIC)[2],
abs(b$WAIC[1,1]-b$WAIC[2,1]), b$WAIC[2,2],
# KFOLD:
ifelse(is.null(b$KFOLD) || all(is.na(b$KFOLD)), "?", rownames(b$KFOLD)[1]),
ifelse(is.null(b$KFOLD) || all(is.na(b$KFOLD)), "?", ifelse(abs(b$KFOLD[1,1]-b$KFOLD[2,1]) < 4 || abs(b$KFOLD[1,1]-b$KFOLD[2,1]) < b$KFOLD[2,2], "≈", ifelse(abs(b$KFOLD[1,1]-b$KFOLD[2,1]) < 2*b$KFOLD[2,2], ">", ">>"))),
ifelse(is.null(b$KFOLD) || all(is.na(b$KFOLD)), "?", rownames(b$KFOLD)[2]),
ifelse(is.null(b$KFOLD) || all(is.na(b$KFOLD)), NA, abs(b$KFOLD[1,1]-b$KFOLD[2,1])), ifelse(is.null(b$KFOLD) || all(is.na(b$KFOLD)), NA, b$KFOLD[2,2]));
# return value:
return (s.b);
}
}
# Standard error of the mean:
std <- function(x) sd(x)/sqrt(length(x))
# Root Mean Square Error (RMSE) between observed (y) and predicted (yrep) values:
rmse <- function(y, yrep)
{
yrep_mean <- colMeans(yrep)
sqrt(mean((yrep_mean - y)^2))
}
# Log odds to probability (logistic regression):
lo2p <- function(x){ o <- exp(x); return (o/(1+o));}
# Scientific notation using Markdown conventions (inspired from https://www.r-bloggers.com/2015/03/scientific-notation-for-rlatex/):
scinot <- function(xs, digits=2, pvalue=TRUE)
{
scinot1 <- function(x)
{
sign <- "";
if(x < 0)
{
sign <- "-";
x <- -x;
}
exponent <- floor(log10(x));
if(exponent && pvalue && exponent < -3)
{
xx <- round(x / 10^exponent, digits=digits);
e <- paste0("×10^", round(exponent,0), "^");
} else
{
xx <- round(x, digits=digits+1);
e <- "";
}
paste0(sign, xx, e);
}
vapply(xs, scinot1, character(1));
}
# Escape * in a string:
escstar <- function(s)
{
gsub("*", "\\*", s, fixed=TRUE);
}
# Chunk 4
packageVersion('tidyverse')
packageVersion('ggplot2')
packageVersion('brms')
#packageVersion('cmdstanr')
packageVersion('ggdist')
# Chunk 5
source('theme_timo.R')
library(maps)
# No margin
par(mar=c(0,0,0,0))
# World map
map('europe',
col="#f2f2f2", fill=TRUE, bg="white", lwd=0.05,
mar=rep(0,4),border=0, ylim=c(-80,80)
)
library(ggplot2)
library(grid)
#library(rworldmap)
library(sf)
#> Linking to GEOS 3.8.0, GDAL 3.0.4, PROJ 6.3.1
library(dplyr)
# Member States of the European Union
europeanUnion <- c("Germany","Poland")
library(rnaturalearth)
install.packages("rnaturalearth")
library(rnaturalearth)
world_map <- ne_countries(scale = 50, returnclass = 'sf')
europe_map <- world_map %>% filter(name %in% europeanUnion)
world_map <- ne_countries(scale = 50, returnclass = 'sf')
# Install and load necessary packages
install.packages("leaflet")
library(leaflet)
# Define the coordinates for the route
coords <- list(
c(51.618679, 19.3668898),
c(52.0367271, 8.4926664),
c(52.4961822, 13.3269518)
)
# Create a leaflet map
map <- leaflet() %>%
# Add tiles
addTiles() %>%
# Add markers for the start and end points
addMarkers(lng = c(19.3668898, 8.4926664, 13.3269518),
lat = c(51.618679, 52.0367271, 52.4961822),
label = c("Start", "Midpoint", "End")) %>%
# Add a line to trace the route
addPolylines(lng = coords[[2]], lat = coords[[1]], color = "red")
# Display the map
map
# Define the coordinates for the route
coords <- list(
c(51.618679, 19.3668898),
c(52.0367271, 8.4926664),
c(52.4961822, 13.3269518)
)
# Create a leaflet map
map <- leaflet() %>%
# Add plain tiles
addProviderTiles("Stamen.TonerLite") %>%
# Add a line to trace the route
addPolylines(lng = coords[[2]], lat = coords[[1]], color = "red")
# Display the map
map
parentfolder <- .
parentfolder <- dirname(.)
parentfolder <- dirname(".")
library(readtextgrid)   #reading txt grids
library(dplyr)
files <- list.files("." ,pattern = "\\.TextGrid$", full.names = TRUE)
files <- list.files(pattern = "\\.TextGrid$", full.names = TRUE)
files <- list.files(parentfolder, pattern = "\\.TextGrid$", full.names = TRUE)
getwd()
setwd(.)
setwd(".")
getwd()
parentfolder = rstudioapi::getActiveDocumentContext()$path
parentfolder = dirname(dirname(parentfolder))
files <- list.files(parentfolder, pattern = "\\.TextGrid$", full.names = TRUE)
parentfolder = dirname(parentfolder)
parentfolder = rstudioapi::getActiveDocumentContext()$path
parentfolder = dirname(parentfolder)
files <- list.files(parentfolder, pattern = "\\.TextGrid$", full.names = TRUE)
tg <- readtextgrid::read_textgrid(files[1])
View(tg)
tg$tier_name
tg
writeTextGrid <- function(data, outputFile) {
# Open a connection to the output file
con <- file(outputFile, "w")
# Write the TextGrid header
cat('File type = "ooTextFile"\n', file = con)
cat('Object class = "TextGrid"\n', file = con)
cat('\n', file = con)  # Add an extra line
cat('xmin = 0 \n', file = con)
cat('xmax =', max(data$xmax), '\n', file = con)
cat('tiers? <exists> \n', file = con)
cat('size =', n_distinct(data$tier_name), '\n', file = con)
cat('item []:', '\n', file = con)
# Write the tier information
tiers <- unique(data[, c("tier_num", "tier_name", "tier_type")])
for (i in 1:nrow(tiers)) {
cat(paste0('    item [', i, ']:\n'), file = con)
cat(paste0('        class = "', tiers$tier_type[i], '"\n'), file = con)
cat(paste0('        name = "', tiers$tier_name[i], '"\n'), file = con)
cat(paste0('        xmin = 0\n'), file = con)
cat(paste0('        xmax = ', max(data$xmax), '\n'), file = con)
# Write intervals or points
if (tiers$tier_type[i] == "IntervalTier") {
intervals <- data[data$tier_name == tiers$tier_name[i], ]
cat(paste0('        intervals: size = ', nrow(intervals), '\n'), file = con)
for (j in 1:nrow(intervals)) {
cat(paste0('        intervals [', j, ']:\n'), file = con)
cat(paste0('            xmin = ', intervals$xmin[j], '\n'), file = con)
cat(paste0('            xmax = ', intervals$xmax[j], '\n'), file = con)
cat(paste0('            text = "', intervals$text[j], '"\n'), file = con)
}
} else if (tiers$tier_type[i] == "PointTier") {
points <- data[data$tier_name == tiers$tier_name[i], ]
cat(paste0('        points: size = ', nrow(points), '\n'), file = con)
for (j in 1:nrow(points)) {
cat(paste0('        points [', j, ']:\n'), file = con)
cat(paste0('            number = ', j - 1, '\n'), file = con)  # Point numbers start from 0
cat(paste0('            time = ', points$xmax[j], '\n'), file = con)  # Assuming xmax as time
cat(paste0('            mark = "', points$text[j], '"\n'), file = con)
}
}
}
# Close the connection
close(con)
}
# Loop through each file
for (textGrid in files) {
# Read the TextGrid file
tg <- readtextgrid::read_textgrid(textGrid)
# Change 'silences' in tier_name to 'vocalization'
tg$tier_name[tg$tier_name == "silences"] <- "vocalization"
# Create a new row to be added
new_row <- tibble(
file = unique(tg$file),
tier_num = max(tg$tier_num) + 1,
tier_name = "gesture",
tier_type = unique(tg$tier_type),
tier_xmin = 0,
tier_xmax = max(tg$tier_xmax),
xmin = 0,
xmax = max(tg$xmax),
text = "no_gesture",
annotation_num = 1
)
# Append the new row to the tibble
tg <- bind_rows(tg, new_row)
# Save the modified TextGrid back to the same file
writeTextGrid(tg, textGrid)
}
files_avi <- list.files(parentfolder, pattern = "\\.avi$", full.names = TRUE)
files
files_avi
head(files)
head(files_avi)
# Create csv for readme on annotating process
# Create a data frame
data <- data.frame(
files = files,
files_avi = files_avi,
comments = rep("", length(files))  # Empty comments column
)
write.csv(data, paste0(parentfolder, "file_comments.csv"), row.names = FALSE)
write.csv(data, paste0(parentfolder, "/file_comments.csv"), row.names = FALSE)
# Create csv for readme on annotating process
# Create a data frame
data <- data.frame(
files = basename(files),
files_avi = basenames(files_avi),
comments = rep("", length(files))  # Empty comments column
)
# Create csv for readme on annotating process
# Create a data frame
data <- data.frame(
files = basename(files),
files_avi = basename(files_avi),
comments = rep("", length(files))  # Empty comments column
)
View(data)
write.csv(data, paste0(parentfolder, "/file_comments.csv"), row.names = FALSE)
# Create a data frame for comments on the files
data <- data.frame(
files = sub("\\.TextGrid$", "", basename(files)),
files_avi = sub("\\.avi$", "", basename(files_avi)),
condition <- ifelse(grepl("geluiden", files), "vocalization",
ifelse(grepl("combinatie", files), "combined",
ifelse(grepl("gebaren", files), "gesture", NA))),
comments_audio = rep("", length(files)),
comments_video = rep("", length(files))
)
View(data)
# Create a data frame for comments on the files
data <- data.frame(
files = sub("\\.TextGrid$", "", basename(files)),
files_avi = sub("\\.avi$", "", basename(files_avi)),
condition = ifelse(grepl("geluiden", files), "vocalization",
ifelse(grepl("combinatie", files), "combined",
ifelse(grepl("gebaren", files), "gesture", NA))),
comments_audio = rep("", length(files)),
comments_video = rep("", length(files))
)
View(data)
write.csv(data, paste0(parentfolder, "/file_comments.csv"), row.names = FALSE)
install.packages("writexl")
library(writexlsx)
library(writexl)
write_xlsx(data, paste0(parentfolder, "/file_comments.xlsx"), row.names = FALSE)
write_xlsx(data, paste0(parentfolder, "/file_comments.xlsx"))
new_names <- sub("\\.avi$", ".TextGrid", basename(files_avi))
new_names_textGrid <- sub("\\.avi$", ".TextGrid", basename(files_avi))
new_names_wav <- sub("\\.avi$", ".wav", basename(files_avi))
new_paths <- file.path(dirname(files_avi), new_names_textGrid)
new_paths
new_paths_textGrid <- file.path(dirname(files_avi), new_names_textGrid)
new_paths_wav <- file.path(dirname(files_avi), new_names_wav)
files
results <- file.rename(files, new_paths_textGrid)
files_wav <- list.files(parentfolder, pattern = "\\.wav$", full.names = TRUE)
results <- file.rename(files_wav, new_paths_wav)
files_wav <- list.files(parentfolder, pattern = "\\.wav$", full.names = TRUE)
files_wav
files_wav <- list.files(parentfolder, pattern = "\\.wav$", full.names = TRUE)
files_wav
results <- file.rename(files_wav, new_paths_wav)
rm(results, new_names, new_names_textGrid, new_names_wav, new_paths, new_paths_textGrid, new_paths_wav, files, files_avi, files_wav)
raw_files <- list.files(directory_path, pattern = "_video_raw.*$", full.names = TRUE)
raw_files <- list.files(parentfolder, pattern = "_video_raw.*$", full.names = TRUE)
head(raw_files)
new_names <- sub("_video_raw(\\.[^.]+)$", "\\1", raw_files)
results <- file.rename(raw_files, new_names)
rm(raw_files, new_names, results)
files_avi <- list.files(parentfolder, pattern = "\\.avi$", full.names = TRUE)
data <- data.frame(
file = sub("\\.avi$", "", basename(files_avi)),
condition = ifelse(grepl("geluiden", files), "vocalization",
ifelse(grepl("combinatie", files), "combined",
ifelse(grepl("gebaren", files), "gesture", NA))),
comments_audio = rep("", length(files)),
comments_video = rep("", length(files))
)
data <- data.frame(
file = sub("\\.avi$", "", basename(files_avi)),
condition = ifelse(grepl("geluiden", files_avi), "vocalization",
ifelse(grepl("combinatie", files_avi), "combined",
ifelse(grepl("gebaren", files_avi), "gesture", NA))),
comments_audio = rep("", length(files_avi)),
comments_video = rep("", length(files_avi))
)
write_xlsx(data, paste0(parentfolder, "/file_comments.xlsx"))
########## folders ##########
library(here)
setwd(getSrcDirectory(function(){})[1])
print(utils::getSrcDirectory(function(){}))
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
########## folders ##########
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
parentfolder <- dirname(getwd())
rawdata       <- paste0(parentfolder, '/rawdata/');
dataset       <- paste0(parentfolder, '/dataset/');
models        <- paste0(parentfolder, '/models/');
plots         <- paste0(parentfolder, '/plots/');
scripts       <- paste0(parentfolder, '/scripts/');
########## source file ##########
#rmarkdown::render("1_descriptive.Rmd", envir = globalenv(), clean = FALSE)
#################### packages ####################
# Data Manipulation
library(tidyverse);
# Plotting
library(corrplot);
library(cowplot);
library(ggdist);
# Bayesian
library(brms);
library(cmdstanr);
library(emmeans);
library(posterior);
library(tidybayes);
theme_set(theme_tidybayes() + panel_border());
# use all available cores for parallel computing
options(mc.cores = parallel::detectCores());
colorBlindBlack8  <- c("#000000", "#E69F00", "#56B4E9", "#009E73",
"#F0E442", "#0072B2", "#D55E00", "#CC79A7")
########## folders ##########
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
parentfolder <- dirname(getwd())
rawdata       <- paste0(parentfolder, '/rawdata/');
dataset       <- paste0(parentfolder, '/dataset/');
models        <- paste0(parentfolder, '/models/');
plots         <- paste0(parentfolder, '/plots/');
scripts       <- paste0(parentfolder, '/scripts/');
########## source file ##########
#rmarkdown::render("1_descriptive.Rmd", envir = globalenv(), clean = FALSE)
#################### packages ####################
# Data Manipulation
library(tidyverse);
# Plotting
library(corrplot);
library(cowplot);
library(ggdist);
# Bayesian
library(brms);
library(cmdstanr);
library(emmeans);
library(posterior);
library(tidybayes);
theme_set(theme_tidybayes() + panel_border());
# use all available cores for parallel computing
options(mc.cores = parallel::detectCores());
colorBlindBlack8  <- c("#000000", "#E69F00", "#56B4E9", "#009E73",
"#F0E442", "#0072B2", "#D55E00", "#CC79A7")
# Load data frame
df <- read_csv(paste0(dataset, "df.csv"))
# Load concept list
concepts <- read_excel(paste0(dataset, "conceptlist_info.xlsx"))
# Load concept list
concepts <- readxl::read_excel(paste0(dataset, "conceptlist_info.xlsx"))
# Load expressibility German
expr_german <- read_csv(paste0(dataset, "expressibility_german.csv"))
# Load expressibility Dutch
expr_dutch <- read_csv(paste0(dataset, "expressibility_dutch.csv"))
df %>%
group_by(concept) %>%
summarise(frequency = n()) %>%
arrange(desc(frequency)) %>%
print(n = 100)
length(df)
nrow(df)
df %>%
group_by(concept, exp_part) %>%
summarise(frequency = n(), .groups = "drop") %>%  # Calculate frequency for each exp_part
pivot_wider(names_from = exp_part, values_from = frequency, names_prefix = "frequency_part") %>%
arrange(desc(frequency_part1), desc(frequency_part2)) %>%
print(n = 100)
df %>% filter(exp_part = "1")
nrow(filter(df,exp_part = "1"))
nrow(filter(df,exp_part == "1"))
df %>%
group_by(concept) %>%
summarise(frequency = n()) %>%
arrange(desc(frequency)) %>%
print(n = 100)
df %>%
group_by(concept, exp_part) %>%
summarise(frequency = n(), .groups = "drop") %>%  # Calculate frequency for each exp_part
pivot_wider(names_from = exp_part, values_from = frequency, names_prefix = "frequency_part") %>%
arrange(desc(frequency_part1), desc(frequency_part2)) %>%
print(n = 100)
nrow(filter(df, modality == "combined" & exp_part == "1"))
str(df)
df %>%
group_by(concept) %>%
summarise(frequency = n()) %>%
arrange(desc(frequency)) %>%
print(n = 100)
df_part2 <- df %>%
filter(exp_part == 2)
str(df)
unique(df$participant_ID)
# Make sure we code the factors with the intended baseline levels and contrasts:
df$guess_binary       <- factor(df$guess_binary, levels = c("0", "1")); contrasts(df$guess_binary) <- c(-0.5, +0.5)
View(df)
str(df)
df %>% count(guess_binary) %>% mutate(prop = paste0(round(100* n / sum(n),1),"%"))
df %>% count(correction) %>% mutate(prop = paste0(round(100* n / sum(n),1),"%"))
df %>% count(guess_binary) %>% mutate(prop = paste0(round(100* n / sum(n),1),"%"))
df %>% count(correction) %>% mutate(prop = paste0(round(100* n / sum(n),1),"%"))
df$guess_binary <- factor(df$guess_binary, levels = c("0", "1")); contrasts(df$guess_binary) <- c(-0.5, +0.5)
## 'cosine_similarity' is continuous, no need to transform it
df$correction <- factor(df$correction, levels = c("0", "1", "2"))
# Predictor variables
## 'expressibility' is continuous, no transformation needed
df$experiment_part <- factor(df$experiment_part, levels = c("1", "2")); contrasts(df$experiment_part) <- c(-0.5, +0.5)
# Predictor variables
## 'expressibility' is continuous, no transformation needed
df$exp_part <- factor(df$experiment_part, levels = c("1", "2")); contrasts(df$exp_part) <- c(-0.5, +0.5)
# Predictor variables
## 'expressibility' is continuous, no transformation needed
df$exp_part <- factor(df$exp_part, levels = c("1", "2")); contrasts(df$exp_part) <- c(-0.5, +0.5)
df$modality <- factor(df$modality, levels = c("combined", "gesture", "vocal"))
# Random variables
df$concept <- factor(df$concept)
df$dyad <- factor(df$dyad)
df$participant_ID <- factor(df$participant_ID)
df %>% count(correction) %>% mutate(prop = paste0(round(100* n / sum(n),1),"%"))
df %>% count(experiment_part) %>% mutate(prop = paste0(round(100* n / sum(n),1),"%"))
df %>% count(exp_part) %>% mutate(prop = paste0(round(100* n / sum(n),1),"%"))
df %>% count(modality) %>% mutate(prop = paste0(round(100* n / sum(n),1),"%"))
df %>% count(concept) %>% mutate(prop = paste0(round(100* n / sum(n),1),"%"))
df %>% count(dyad) %>% mutate(prop = paste0(round(100* n / sum(n),1),"%"))
df %>% count(participant_ID) %>% mutate(prop = paste0(round(100* n / sum(n),1),"%"))
df %>% count(participant_ID) %>% mutate(prop = paste0(round(100* n / sum(n),1),"%"))
