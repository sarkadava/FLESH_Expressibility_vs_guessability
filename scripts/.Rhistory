# Bayesian comparison:
if( !is.null(b) )
{
s.b <- sprintf("BF: %s, ΔLOO(%s %s %s)=%.1f (%.1f), ΔWAIC(%s %s %s)=%.1f (%.1f), ΔKFOLD(%s %s %s)=%.1f (%.1f)",
# BF:
b$BF_interpretation,
# LOO:
rownames(b$LOO)[1],
ifelse(abs(b$LOO[1,1]-b$LOO[2,1]) < 4 || abs(b$LOO[1,1]-b$LOO[2,1]) < b$LOO[2,2], "≈", ifelse(abs(b$LOO[1,1]-b$LOO[2,1]) < 2*b$LOO[2,2], ">", ">>")),
rownames(b$LOO)[2],
abs(b$LOO[1,1]-b$LOO[2,1]), b$LOO[2,2],
# WAIC:
rownames(b$WAIC)[1],
ifelse(abs(b$WAIC[1,1]-b$WAIC[2,1]) < 4 || abs(b$WAIC[1,1]-b$WAIC[2,1]) < b$WAIC[2,2], "≈", ifelse(abs(b$WAIC[1,1]-b$WAIC[2,1]) < 2*b$WAIC[2,2], ">", ">>")),
rownames(b$WAIC)[2],
abs(b$WAIC[1,1]-b$WAIC[2,1]), b$WAIC[2,2],
# KFOLD:
ifelse(is.null(b$KFOLD) || all(is.na(b$KFOLD)), "?", rownames(b$KFOLD)[1]),
ifelse(is.null(b$KFOLD) || all(is.na(b$KFOLD)), "?", ifelse(abs(b$KFOLD[1,1]-b$KFOLD[2,1]) < 4 || abs(b$KFOLD[1,1]-b$KFOLD[2,1]) < b$KFOLD[2,2], "≈", ifelse(abs(b$KFOLD[1,1]-b$KFOLD[2,1]) < 2*b$KFOLD[2,2], ">", ">>"))),
ifelse(is.null(b$KFOLD) || all(is.na(b$KFOLD)), "?", rownames(b$KFOLD)[2]),
ifelse(is.null(b$KFOLD) || all(is.na(b$KFOLD)), NA, abs(b$KFOLD[1,1]-b$KFOLD[2,1])), ifelse(is.null(b$KFOLD) || all(is.na(b$KFOLD)), NA, b$KFOLD[2,2]));
# return value:
return (s.b);
}
}
# Standard error of the mean:
std <- function(x) sd(x)/sqrt(length(x))
# Root Mean Square Error (RMSE) between observed (y) and predicted (yrep) values:
rmse <- function(y, yrep)
{
yrep_mean <- colMeans(yrep)
sqrt(mean((yrep_mean - y)^2))
}
# Log odds to probability (logistic regression):
lo2p <- function(x){ o <- exp(x); return (o/(1+o));}
# Scientific notation using Markdown conventions (inspired from https://www.r-bloggers.com/2015/03/scientific-notation-for-rlatex/):
scinot <- function(xs, digits=2, pvalue=TRUE)
{
scinot1 <- function(x)
{
sign <- "";
if(x < 0)
{
sign <- "-";
x <- -x;
}
exponent <- floor(log10(x));
if(exponent && pvalue && exponent < -3)
{
xx <- round(x / 10^exponent, digits=digits);
e <- paste0("×10^", round(exponent,0), "^");
} else
{
xx <- round(x, digits=digits+1);
e <- "";
}
paste0(sign, xx, e);
}
vapply(xs, scinot1, character(1));
}
# Escape * in a string:
escstar <- function(s)
{
gsub("*", "\\*", s, fixed=TRUE);
}
# Chunk 4
packageVersion('tidyverse')
packageVersion('ggplot2')
packageVersion('brms')
#packageVersion('cmdstanr')
packageVersion('ggdist')
# Chunk 5
source('theme_timo.R')
library(maps)
# No margin
par(mar=c(0,0,0,0))
# World map
map('europe',
col="#f2f2f2", fill=TRUE, bg="white", lwd=0.05,
mar=rep(0,4),border=0, ylim=c(-80,80)
)
library(ggplot2)
library(grid)
#library(rworldmap)
library(sf)
#> Linking to GEOS 3.8.0, GDAL 3.0.4, PROJ 6.3.1
library(dplyr)
# Member States of the European Union
europeanUnion <- c("Germany","Poland")
library(rnaturalearth)
install.packages("rnaturalearth")
library(rnaturalearth)
world_map <- ne_countries(scale = 50, returnclass = 'sf')
europe_map <- world_map %>% filter(name %in% europeanUnion)
world_map <- ne_countries(scale = 50, returnclass = 'sf')
# Install and load necessary packages
install.packages("leaflet")
library(leaflet)
# Define the coordinates for the route
coords <- list(
c(51.618679, 19.3668898),
c(52.0367271, 8.4926664),
c(52.4961822, 13.3269518)
)
# Create a leaflet map
map <- leaflet() %>%
# Add tiles
addTiles() %>%
# Add markers for the start and end points
addMarkers(lng = c(19.3668898, 8.4926664, 13.3269518),
lat = c(51.618679, 52.0367271, 52.4961822),
label = c("Start", "Midpoint", "End")) %>%
# Add a line to trace the route
addPolylines(lng = coords[[2]], lat = coords[[1]], color = "red")
# Display the map
map
# Define the coordinates for the route
coords <- list(
c(51.618679, 19.3668898),
c(52.0367271, 8.4926664),
c(52.4961822, 13.3269518)
)
# Create a leaflet map
map <- leaflet() %>%
# Add plain tiles
addProviderTiles("Stamen.TonerLite") %>%
# Add a line to trace the route
addPolylines(lng = coords[[2]], lat = coords[[1]], color = "red")
# Display the map
map
parentfolder <- .
parentfolder <- dirname(.)
parentfolder <- dirname(".")
library(readtextgrid)   #reading txt grids
library(dplyr)
files <- list.files("." ,pattern = "\\.TextGrid$", full.names = TRUE)
files <- list.files(pattern = "\\.TextGrid$", full.names = TRUE)
files <- list.files(parentfolder, pattern = "\\.TextGrid$", full.names = TRUE)
getwd()
setwd(.)
setwd(".")
getwd()
parentfolder = rstudioapi::getActiveDocumentContext()$path
parentfolder = dirname(dirname(parentfolder))
files <- list.files(parentfolder, pattern = "\\.TextGrid$", full.names = TRUE)
parentfolder = dirname(parentfolder)
parentfolder = rstudioapi::getActiveDocumentContext()$path
parentfolder = dirname(parentfolder)
files <- list.files(parentfolder, pattern = "\\.TextGrid$", full.names = TRUE)
tg <- readtextgrid::read_textgrid(files[1])
View(tg)
tg$tier_name
tg
writeTextGrid <- function(data, outputFile) {
# Open a connection to the output file
con <- file(outputFile, "w")
# Write the TextGrid header
cat('File type = "ooTextFile"\n', file = con)
cat('Object class = "TextGrid"\n', file = con)
cat('\n', file = con)  # Add an extra line
cat('xmin = 0 \n', file = con)
cat('xmax =', max(data$xmax), '\n', file = con)
cat('tiers? <exists> \n', file = con)
cat('size =', n_distinct(data$tier_name), '\n', file = con)
cat('item []:', '\n', file = con)
# Write the tier information
tiers <- unique(data[, c("tier_num", "tier_name", "tier_type")])
for (i in 1:nrow(tiers)) {
cat(paste0('    item [', i, ']:\n'), file = con)
cat(paste0('        class = "', tiers$tier_type[i], '"\n'), file = con)
cat(paste0('        name = "', tiers$tier_name[i], '"\n'), file = con)
cat(paste0('        xmin = 0\n'), file = con)
cat(paste0('        xmax = ', max(data$xmax), '\n'), file = con)
# Write intervals or points
if (tiers$tier_type[i] == "IntervalTier") {
intervals <- data[data$tier_name == tiers$tier_name[i], ]
cat(paste0('        intervals: size = ', nrow(intervals), '\n'), file = con)
for (j in 1:nrow(intervals)) {
cat(paste0('        intervals [', j, ']:\n'), file = con)
cat(paste0('            xmin = ', intervals$xmin[j], '\n'), file = con)
cat(paste0('            xmax = ', intervals$xmax[j], '\n'), file = con)
cat(paste0('            text = "', intervals$text[j], '"\n'), file = con)
}
} else if (tiers$tier_type[i] == "PointTier") {
points <- data[data$tier_name == tiers$tier_name[i], ]
cat(paste0('        points: size = ', nrow(points), '\n'), file = con)
for (j in 1:nrow(points)) {
cat(paste0('        points [', j, ']:\n'), file = con)
cat(paste0('            number = ', j - 1, '\n'), file = con)  # Point numbers start from 0
cat(paste0('            time = ', points$xmax[j], '\n'), file = con)  # Assuming xmax as time
cat(paste0('            mark = "', points$text[j], '"\n'), file = con)
}
}
}
# Close the connection
close(con)
}
# Loop through each file
for (textGrid in files) {
# Read the TextGrid file
tg <- readtextgrid::read_textgrid(textGrid)
# Change 'silences' in tier_name to 'vocalization'
tg$tier_name[tg$tier_name == "silences"] <- "vocalization"
# Create a new row to be added
new_row <- tibble(
file = unique(tg$file),
tier_num = max(tg$tier_num) + 1,
tier_name = "gesture",
tier_type = unique(tg$tier_type),
tier_xmin = 0,
tier_xmax = max(tg$tier_xmax),
xmin = 0,
xmax = max(tg$xmax),
text = "no_gesture",
annotation_num = 1
)
# Append the new row to the tibble
tg <- bind_rows(tg, new_row)
# Save the modified TextGrid back to the same file
writeTextGrid(tg, textGrid)
}
files_avi <- list.files(parentfolder, pattern = "\\.avi$", full.names = TRUE)
files
files_avi
head(files)
head(files_avi)
# Create csv for readme on annotating process
# Create a data frame
data <- data.frame(
files = files,
files_avi = files_avi,
comments = rep("", length(files))  # Empty comments column
)
write.csv(data, paste0(parentfolder, "file_comments.csv"), row.names = FALSE)
write.csv(data, paste0(parentfolder, "/file_comments.csv"), row.names = FALSE)
# Create csv for readme on annotating process
# Create a data frame
data <- data.frame(
files = basename(files),
files_avi = basenames(files_avi),
comments = rep("", length(files))  # Empty comments column
)
# Create csv for readme on annotating process
# Create a data frame
data <- data.frame(
files = basename(files),
files_avi = basename(files_avi),
comments = rep("", length(files))  # Empty comments column
)
View(data)
write.csv(data, paste0(parentfolder, "/file_comments.csv"), row.names = FALSE)
# Create a data frame for comments on the files
data <- data.frame(
files = sub("\\.TextGrid$", "", basename(files)),
files_avi = sub("\\.avi$", "", basename(files_avi)),
condition <- ifelse(grepl("geluiden", files), "vocalization",
ifelse(grepl("combinatie", files), "combined",
ifelse(grepl("gebaren", files), "gesture", NA))),
comments_audio = rep("", length(files)),
comments_video = rep("", length(files))
)
View(data)
# Create a data frame for comments on the files
data <- data.frame(
files = sub("\\.TextGrid$", "", basename(files)),
files_avi = sub("\\.avi$", "", basename(files_avi)),
condition = ifelse(grepl("geluiden", files), "vocalization",
ifelse(grepl("combinatie", files), "combined",
ifelse(grepl("gebaren", files), "gesture", NA))),
comments_audio = rep("", length(files)),
comments_video = rep("", length(files))
)
View(data)
write.csv(data, paste0(parentfolder, "/file_comments.csv"), row.names = FALSE)
install.packages("writexl")
library(writexlsx)
library(writexl)
write_xlsx(data, paste0(parentfolder, "/file_comments.xlsx"), row.names = FALSE)
write_xlsx(data, paste0(parentfolder, "/file_comments.xlsx"))
new_names <- sub("\\.avi$", ".TextGrid", basename(files_avi))
new_names_textGrid <- sub("\\.avi$", ".TextGrid", basename(files_avi))
new_names_wav <- sub("\\.avi$", ".wav", basename(files_avi))
new_paths <- file.path(dirname(files_avi), new_names_textGrid)
new_paths
new_paths_textGrid <- file.path(dirname(files_avi), new_names_textGrid)
new_paths_wav <- file.path(dirname(files_avi), new_names_wav)
files
results <- file.rename(files, new_paths_textGrid)
files_wav <- list.files(parentfolder, pattern = "\\.wav$", full.names = TRUE)
results <- file.rename(files_wav, new_paths_wav)
files_wav <- list.files(parentfolder, pattern = "\\.wav$", full.names = TRUE)
files_wav
files_wav <- list.files(parentfolder, pattern = "\\.wav$", full.names = TRUE)
files_wav
results <- file.rename(files_wav, new_paths_wav)
rm(results, new_names, new_names_textGrid, new_names_wav, new_paths, new_paths_textGrid, new_paths_wav, files, files_avi, files_wav)
raw_files <- list.files(directory_path, pattern = "_video_raw.*$", full.names = TRUE)
raw_files <- list.files(parentfolder, pattern = "_video_raw.*$", full.names = TRUE)
head(raw_files)
new_names <- sub("_video_raw(\\.[^.]+)$", "\\1", raw_files)
results <- file.rename(raw_files, new_names)
rm(raw_files, new_names, results)
files_avi <- list.files(parentfolder, pattern = "\\.avi$", full.names = TRUE)
data <- data.frame(
file = sub("\\.avi$", "", basename(files_avi)),
condition = ifelse(grepl("geluiden", files), "vocalization",
ifelse(grepl("combinatie", files), "combined",
ifelse(grepl("gebaren", files), "gesture", NA))),
comments_audio = rep("", length(files)),
comments_video = rep("", length(files))
)
data <- data.frame(
file = sub("\\.avi$", "", basename(files_avi)),
condition = ifelse(grepl("geluiden", files_avi), "vocalization",
ifelse(grepl("combinatie", files_avi), "combined",
ifelse(grepl("gebaren", files_avi), "gesture", NA))),
comments_audio = rep("", length(files_avi)),
comments_video = rep("", length(files_avi))
)
write_xlsx(data, paste0(parentfolder, "/file_comments.xlsx"))
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2: source setup
########## folders ##########
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
########## folders ##########
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
parentfolder <- dirname(getwd())
rawdata       <- paste0(parentfolder, '/rawdata/')
dataset       <- paste0(parentfolder, '/dataset/')
models        <- paste0(parentfolder, '/models/')
plots         <- paste0(parentfolder, '/plots/')
scripts       <- paste0(parentfolder, '/scripts/')
#################### packages ####################
# Data Manipulation
library(tibble)
library(stringr)
library(tidyverse) # includes readr, tidyr, dplyr, ggplot2
packageVersion("tidyverse")
library(data.table)
library(readxl)
# Plotting
library(ggforce)
library(ggpubr)
library(gridExtra)
library(corrplot)
library(ggdist)
library(ggbeeswarm)
library(BayesFactor)
# use all available cores for parallel computing
options(mc.cores = parallel::detectCores())
colorBlindBlack8  <- c("#000000", "#E69F00", "#56B4E9", "#009E73",
"#F0E442", "#0072B2", "#D55E00", "#CC79A7")
# Load data frame
df <- read_csv(paste0(dataset, "similarity_df_final.csv"))
# Load concept list
concepts <- read_excel(paste0(dataset, "conceptlist_info.xlsx"))
# Load expressibility German
expr_german <- read_csv(paste0(dataset, "expressibility_german.csv"))
# Load expressibility Dutch
expr_dutch <- read_csv(paste0(dataset, "expressibility_dutch.csv"))
df <- df %>%
mutate(
modality = case_when(
modality == "combinatie" ~ "combined",
modality == "gebaren" ~ "gesture",
modality == "geluiden" ~ "vocal",
TRUE ~ modality
)
) %>%
rename(participant_dyad = participant) %>%
rename(participant_ID = pcnID) %>%
rename(concept = English) %>%
select(-`...1`) %>%  # Remove the first column
rename(stimulus = word)
# Reorder the columns in the specified order
df <- df %>%
select(trial_order, trial_type,
dyad, participant_dyad, participant_ID, exp_part, modality,
expressibility_dutch, concept, correction,
guess_binary, cosine_similarity, stimulus, answer,
SemanticSubcat, sessionID)
# Only keep target trials
df <- df %>%
filter(trial_type == "target")%>%
select(-`trial_type`) # Remove trial_type columns
length(unique(df$dyad))
length(unique(df$participant_ID))
length(unique(df$concept))
length(unique(df$stimulus))
df %>%
group_by(modality) %>%
summarise(frequency = n()) %>%
arrange(desc(frequency)) %>%
print(n = 100)
df %>%
group_by(exp_part) %>%
summarise(frequency = n()) %>%
arrange(desc(frequency)) %>%
print(n = 100)
# For experiment part 2
df %>%
filter(exp_part == 2) %>%  # Filter for experiment part 2
group_by(concept, modality) %>%
summarise(frequency = n(), .groups = "drop") %>%  # Calculate frequency for each concept and modality
ggplot(aes(x = concept, y = frequency, fill = modality)) +  # Set up the plot
geom_bar(stat = "identity", position = "stack") +  # Use stacked bars to show counts
scale_fill_manual(values = colorBlindBlack8[1:3]) +  # Use first 3 colors from colorBlindBlack8 for modalities
labs(
x = "Concept",
y = "Frequency (experiment part 2)",
fill = "Modality"
) +
theme_minimal() +
theme(
axis.text.x = element_text(angle = 45, hjust = 1),  # Rotate x-axis labels for readability
text = element_text(size = 14)
) +
coord_flip()  # Flip coordinates to make the plot more readable
df %>%
group_by(concept, exp_part) %>%
summarise(frequency = n(), .groups = "drop") %>%  # Calculate frequency for each exp_part
pivot_wider(names_from = exp_part, values_from = frequency, names_prefix = "frequency_part") %>%
arrange(desc(frequency_part1), desc(frequency_part2)) %>%
print(n = 100)
df %>%
group_by(exp_part, modality) %>%
summarise(frequency = n(), .groups = "drop") %>%  # Calculate frequency for each concept and modality
pivot_wider(names_from = modality, values_from = frequency, names_prefix = "modality_") %>%
#arrange(desc(modality_combined), desc(modality_gesture), desc(modality_vocal)) %>%  # Sort by modality frequencies
print(n = 100)
length(unique(df))
nrow(df)
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2: source setup
########## folders ##########
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
parentfolder <- dirname(getwd())
rawdata       <- paste0(parentfolder, '/rawdata/')
dataset       <- paste0(parentfolder, '/dataset/')
models        <- paste0(parentfolder, '/models/')
plots         <- paste0(parentfolder, '/plots/')
scripts       <- paste0(parentfolder, '/scripts/')
########## source file ##########
#source(paste0(scripts, "adjectives-preparation.R"))
#################### packages ####################
# Data Manipulation
library(tibble)
library(stringr)
library(tidyverse) # includes readr, tidyr, dplyr, ggplot2
packageVersion("tidyverse")
library(data.table)
library(readxl)
# Plotting
library(ggforce)
library(ggpubr)
library(gridExtra)
library(corrplot)
library(ggdist)
library(ggbeeswarm)
library(BayesFactor)
# use all available cores for parallel computing
options(mc.cores = parallel::detectCores())
colorBlindBlack8  <- c("#000000", "#E69F00", "#56B4E9", "#009E73",
"#F0E442", "#0072B2", "#D55E00", "#CC79A7")
# Chunk 3: read metadata
# Load data frame
df <- read_csv(paste0(dataset, "similarity_df_final.csv"))
# Load concept list
concepts <- read_excel(paste0(dataset, "conceptlist_info.xlsx"))
# Load expressibility German
expr_german <- read_csv(paste0(dataset, "expressibility_german.csv"))
# Load expressibility Dutch
expr_dutch <- read_csv(paste0(dataset, "expressibility_dutch.csv"))
# Chunk 4
df <- df %>%
mutate(
modality = case_when(
modality == "combinatie" ~ "combined",
modality == "gebaren" ~ "gesture",
modality == "geluiden" ~ "vocal",
TRUE ~ modality
)
) %>%
rename(participant_dyad = participant) %>%
rename(participant_ID = pcnID) %>%
rename(concept = English) %>%
select(-`...1`) %>%  # Remove the first column
rename(stimulus = word)
# Reorder the columns in the specified order
df <- df %>%
select(trial_order, trial_type,
dyad, participant_dyad, participant_ID, exp_part, modality,
expressibility_dutch, concept, correction,
guess_binary, cosine_similarity, stimulus, answer,
SemanticSubcat, sessionID)
# Only keep target trials
df <- df %>%
filter(trial_type == "target")%>%
select(-`trial_type`) # Remove trial_type columns
# Chunk 5
# exclude here (make to NA)
View(concepts)
length(unique(df$dyad))
length(unique(df$participant_ID))
length(unique(df$concept))
length(unique(df$stimulus))
(unique(df$concept)
)
View(concepts)
View(expr_dutch)
